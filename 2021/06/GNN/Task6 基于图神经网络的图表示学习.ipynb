{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**前言**：本节内容是 [Datawhale六月组队学习 - 图神经网络- Task6 基于图神经网络的图表示学习](https://github.com/datawhalechina/team-learning-nlp/tree/master/GNN/Markdown%E7%89%88%E6%9C%AC) 的学习笔记，学习周期4天"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:20:45.600271Z",
     "start_time": "2021-07-05T14:20:45.587378Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import DataLoader\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "from torch_geometric.nn import global_add_pool, global_mean_pool, global_max_pool, GlobalAttention, Set2Set, MessagePassing\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import argparse\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "### importing OGB\n",
    "from ogb.graphproppred import PygGraphPropPredDataset, Evaluator\n",
    "from ogb.graphproppred.mol_encoder import AtomEncoder, BondEncoder\n",
    "from ogb.utils.features import get_atom_feature_dims, get_bond_feature_dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于图同构网络（GIN）的图表征网络的实现\n",
    "基于图同构网络的图表征学习主要包含以下两个过程：\n",
    "- 首先计算得到节点表征；\n",
    "- 其次对图上各个节点的表征做图池化（Graph Pooling），或称为图读出（Graph Readout），得到图的表征（Graph Representation）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GINGraphRepr--图同构网络的图表征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:15:21.956908Z",
     "start_time": "2021-07-05T14:15:21.942297Z"
    }
   },
   "outputs": [],
   "source": [
    "class GINGraphRepr(nn.Module):\n",
    "\n",
    "    def __init__(self, num_tasks=1, num_layers=5, emb_dim=300, residual=False, drop_ratio=0, JK=\"last\", graph_pooling=\"sum\"):\n",
    "        \"\"\"GIN Graph Pooling Module\n",
    "        Args:\n",
    "            num_tasks (int, optional): number of labels to be predicted. Defaults to 1 (控制了图表征的维度，dimension of graph representation).\n",
    "            num_layers (int, optional): number of GINConv layers. Defaults to 5.\n",
    "            emb_dim (int, optional): dimension of node embedding. Defaults to 300.\n",
    "            residual (bool, optional): adding residual connection or not. Defaults to False.\n",
    "            drop_ratio (float, optional): dropout rate. Defaults to 0.\n",
    "            JK (str, optional): 可选的值为\"last\"和\"sum\"。选\"last\"，只取最后一层的结点的嵌入，选\"sum\"对各层的结点的嵌入求和。Defaults to \"last\".\n",
    "            graph_pooling (str, optional): pooling method of node embedding. 可选的值为\"sum\"，\"mean\"，\"max\"，\"attention\"和\"set2set\"。 Defaults to \"sum\".\n",
    "\n",
    "        Out:\n",
    "            graph representation\n",
    "        \"\"\"\n",
    "        super(GINGraphPooling, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        if self.num_layers < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.gnn_node = GINNodeEmbedding(num_layers, emb_dim, JK=JK, drop_ratio=drop_ratio, residual=residual)\n",
    "\n",
    "        # Pooling function to generate whole-graph embeddings\n",
    "        if graph_pooling == \"sum\":\n",
    "            self.pool = global_add_pool\n",
    "        elif graph_pooling == \"mean\":\n",
    "            self.pool = global_mean_pool\n",
    "        elif graph_pooling == \"max\":\n",
    "            self.pool = global_max_pool\n",
    "        elif graph_pooling == \"attention\":\n",
    "            self.pool = GlobalAttention(gate_nn=nn.Sequential(\n",
    "                nn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(), nn.Linear(emb_dim, 1)))\n",
    "        elif graph_pooling == \"set2set\":\n",
    "            self.pool = Set2Set(emb_dim, processing_steps=2)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "\n",
    "        if graph_pooling == \"set2set\":\n",
    "            self.graph_pred_linear = nn.Linear(2*self.emb_dim, self.num_tasks)\n",
    "        else:\n",
    "            self.graph_pred_linear = nn.Linear(self.emb_dim, self.num_tasks)\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        h_node = self.gnn_node(batched_data)\n",
    "\n",
    "        h_graph = self.pool(h_node, batched_data.batch)\n",
    "        output = self.graph_pred_linear(h_graph)\n",
    "\n",
    "        if self.training:\n",
    "            return output\n",
    "        else:\n",
    "            # At inference time, relu is applied to output to ensure positivity\n",
    "            # 因为预测目标的取值范围就在 (0, 50] 内\n",
    "            return torch.clamp(output, min=0, max=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GINNodeEmbedding--图同构网络的节点嵌入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:15:23.049167Z",
     "start_time": "2021-07-05T14:15:23.032165Z"
    }
   },
   "outputs": [],
   "source": [
    "# GNN to generate node embedding\n",
    "class GINNodeEmbedding(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Output:\n",
    "        node representations\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_layers, emb_dim, drop_ratio=0.5, JK=\"last\", residual=False):\n",
    "        \"\"\"GIN Node Embedding Module\"\"\"\n",
    "\n",
    "        super(GINNodeEmbedding, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        # add residual connection or not\n",
    "        self.residual = residual\n",
    "\n",
    "        if self.num_layers < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.atom_encoder = AtomEncoder(emb_dim)\n",
    "\n",
    "        # List of GNNs\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.batch_norms = torch.nn.ModuleList()\n",
    "\n",
    "        for layer in range(num_layers):\n",
    "            self.convs.append(GINConv(emb_dim))\n",
    "            self.batch_norms.append(torch.nn.BatchNorm1d(emb_dim))\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        x, edge_index, edge_attr = batched_data.x, batched_data.edge_index, batched_data.edge_attr\n",
    "\n",
    "        # computing input node embedding\n",
    "        h_list = [self.atom_encoder(x)]  # 先将类别型原子属性转化为原子表征\n",
    "        for layer in range(self.num_layers):\n",
    "            h = self.convs[layer](h_list[layer], edge_index, edge_attr)\n",
    "            h = self.batch_norms[layer](h)\n",
    "            if layer == self.num_layers - 1:\n",
    "                # remove relu for the last layer\n",
    "                h = F.dropout(h, self.drop_ratio, training=self.training)\n",
    "            else:\n",
    "                h = F.dropout(F.relu(h), self.drop_ratio, training=self.training)\n",
    "\n",
    "            if self.residual:\n",
    "                h += h_list[layer]\n",
    "\n",
    "            h_list.append(h)\n",
    "\n",
    "        # Different implementations of Jk-concat\n",
    "        if self.JK == \"last\":\n",
    "            node_representation = h_list[-1]\n",
    "        elif self.JK == \"sum\":\n",
    "            node_representation = 0\n",
    "            for layer in range(self.num_layers + 1):\n",
    "                node_representation += h_list[layer]\n",
    "\n",
    "        return node_representation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GINConv--图同构卷积层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:15:23.919127Z",
     "start_time": "2021-07-05T14:15:23.905158Z"
    }
   },
   "outputs": [],
   "source": [
    "### GIN convolution along the graph structure\n",
    "class GINConv(MessagePassing):\n",
    "    def __init__(self, emb_dim):\n",
    "        '''\n",
    "            emb_dim (int): node embedding dimensionality\n",
    "        '''\n",
    "        super(GINConv, self).__init__(aggr = \"add\")\n",
    "\n",
    "        self.mlp = nn.Sequential(nn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(), nn.Linear(emb_dim, emb_dim))\n",
    "        self.eps = nn.Parameter(torch.Tensor([0]))\n",
    "        self.bond_encoder = BondEncoder(emb_dim = emb_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr):\n",
    "        edge_embedding = self.bond_encoder(edge_attr) # 先将类别型边属性转换为边表征\n",
    "        out = self.mlp((1 + self.eps) *x + self.propagate(edge_index, x=x, edge_attr=edge_embedding))\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j, edge_attr):\n",
    "        return F.relu(x_j + edge_attr)\n",
    "        \n",
    "    def update(self, aggr_out):\n",
    "        return aggr_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:16:10.831054Z",
     "start_time": "2021-07-05T14:16:10.806408Z"
    }
   },
   "source": [
    "#### GINGraphPooling--图同构池化层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:16:12.633731Z",
     "start_time": "2021-07-05T14:16:12.623372Z"
    }
   },
   "outputs": [],
   "source": [
    "class GINGraphPooling(nn.Module):\n",
    "\n",
    "    def __init__(self, num_tasks=1, num_layers=5, emb_dim=300, residual=False, drop_ratio=0, JK=\"last\", graph_pooling=\"sum\"):\n",
    "        \"\"\"GIN Graph Pooling Module\n",
    "        Args:\n",
    "            num_tasks (int, optional): number of labels to be predicted. Defaults to 1 (控制了图表征的维度，dimension of graph representation).\n",
    "            num_layers (int, optional): number of GINConv layers. Defaults to 5.\n",
    "            emb_dim (int, optional): dimension of node embedding. Defaults to 300.\n",
    "            residual (bool, optional): adding residual connection or not. Defaults to False.\n",
    "            drop_ratio (float, optional): dropout rate. Defaults to 0.\n",
    "            JK (str, optional): 可选的值为\"last\"和\"sum\"。选\"last\"，只取最后一层的结点的嵌入，选\"sum\"对各层的结点的嵌入求和。Defaults to \"last\".\n",
    "            graph_pooling (str, optional): pooling method of node embedding. 可选的值为\"sum\"，\"mean\"，\"max\"，\"attention\"和\"set2set\"。 Defaults to \"sum\".\n",
    "\n",
    "        Out:\n",
    "            graph representation\n",
    "        \"\"\"\n",
    "        super(GINGraphPooling, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.drop_ratio = drop_ratio\n",
    "        self.JK = JK\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_tasks = num_tasks\n",
    "\n",
    "        if self.num_layers < 2:\n",
    "            raise ValueError(\"Number of GNN layers must be greater than 1.\")\n",
    "\n",
    "        self.gnn_node = GINNodeEmbedding(num_layers, emb_dim, JK=JK, drop_ratio=drop_ratio, residual=residual)\n",
    "\n",
    "        # Pooling function to generate whole-graph embeddings\n",
    "        if graph_pooling == \"sum\":\n",
    "            self.pool = global_add_pool\n",
    "        elif graph_pooling == \"mean\":\n",
    "            self.pool = global_mean_pool\n",
    "        elif graph_pooling == \"max\":\n",
    "            self.pool = global_max_pool\n",
    "        elif graph_pooling == \"attention\":\n",
    "            self.pool = GlobalAttention(gate_nn=nn.Sequential(\n",
    "                nn.Linear(emb_dim, emb_dim), nn.BatchNorm1d(emb_dim), nn.ReLU(), nn.Linear(emb_dim, 1)))\n",
    "        elif graph_pooling == \"set2set\":\n",
    "            self.pool = Set2Set(emb_dim, processing_steps=2)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid graph pooling type.\")\n",
    "\n",
    "        if graph_pooling == \"set2set\":\n",
    "            self.graph_pred_linear = nn.Linear(2*self.emb_dim, self.num_tasks)\n",
    "        else:\n",
    "            self.graph_pred_linear = nn.Linear(self.emb_dim, self.num_tasks)\n",
    "\n",
    "    def forward(self, batched_data):\n",
    "        h_node = self.gnn_node(batched_data)\n",
    "\n",
    "        h_graph = self.pool(h_node, batched_data.batch)\n",
    "        output = self.graph_pred_linear(h_graph)\n",
    "\n",
    "        if self.training:\n",
    "            return output\n",
    "        else:\n",
    "            # At inference time, relu is applied to output to ensure positivity\n",
    "            # 因为预测目标的取值范围就在 (0, 50] 内\n",
    "            return torch.clamp(output, min=0, max=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AtomEncoder 与 BondEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:16:13.364422Z",
     "start_time": "2021-07-05T14:16:13.357751Z"
    }
   },
   "outputs": [],
   "source": [
    "full_atom_feature_dims = get_atom_feature_dims()\n",
    "full_bond_feature_dims = get_bond_feature_dims()\n",
    "\n",
    "class AtomEncoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, emb_dim):\n",
    "        super(AtomEncoder, self).__init__()\n",
    "        \n",
    "        self.atom_embedding_list = torch.nn.ModuleList()\n",
    "\n",
    "        for i, dim in enumerate(full_atom_feature_dims):\n",
    "            emb = torch.nn.Embedding(dim, emb_dim)\n",
    "            torch.nn.init.xavier_uniform_(emb.weight.data)\n",
    "            self.atom_embedding_list.append(emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_embedding = 0\n",
    "        for i in range(x.shape[1]):\n",
    "            x_embedding += self.atom_embedding_list[i](x[:,i])\n",
    "\n",
    "        return x_embedding\n",
    "\n",
    "\n",
    "class BondEncoder(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, emb_dim):\n",
    "        super(BondEncoder, self).__init__()\n",
    "        \n",
    "        self.bond_embedding_list = torch.nn.ModuleList()\n",
    "\n",
    "        for i, dim in enumerate(full_bond_feature_dims):\n",
    "            emb = torch.nn.Embedding(dim, emb_dim)\n",
    "            torch.nn.init.xavier_uniform_(emb.weight.data)\n",
    "            self.bond_embedding_list.append(emb)\n",
    "\n",
    "    def forward(self, edge_attr):\n",
    "        bond_embedding = 0\n",
    "        for i in range(edge_attr.shape[1]):\n",
    "            bond_embedding += self.bond_embedding_list[i](edge_attr[:,i])\n",
    "\n",
    "        return bond_embedding   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用GIN进行测试\n",
    "该部分有参考学员的博客：https://wenkangwei.github.io/2021/07/04/GNN-6-GIN-GraphRepresentation/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-05T14:24:23.644026Z",
     "start_time": "2021-07-05T14:20:48.059050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====Epoch 1\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "476b6129a0cb4cbaa087b33ea2d24124",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84035ed99e6d4e3796d1a8a8f1b7c704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b4e909b9f934dd3a63a76879136a2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486c703b16034746bfc487465fcc69d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train': {'rocauc': 0.5829292918471214}, 'Validation': {'rocauc': 0.6131993435234175}, 'Test': {'rocauc': 0.6165144170416578}}\n",
      "=====Epoch 2\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b7764e0beea47e39e4491ea70e8f6f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edc86582412419a8d97d6a9c2099a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65825ac1ce6a4abebe1d1b2d58a1d1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e95309570ab74d7f9156aa005035caf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train': {'rocauc': 0.5020292207792207}, 'Validation': {'rocauc': 0.5123456790123457}, 'Test': {'rocauc': 0.49987446648255085}}\n",
      "=====Epoch 3\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe2d801e61b4b25961e997509485afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce24114c64f444aa0023929ef0825af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e019758db04c3082e2a5125a40dcc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bce90937684cfdab7617a8901860ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train': {'rocauc': 0.5233124141638779}, 'Validation': {'rocauc': 0.5428577552420144}, 'Test': {'rocauc': 0.5143687595357191}}\n",
      "=====Epoch 4\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40800f28349c4f1996783d00d4360c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "799040f01d1e4f77bc236dc3de9ea038",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53619f31c044280bb77b3d8d5e2533f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b884fefe8ad43d2a145de4b95c16b8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train': {'rocauc': 0.5417989108526384}, 'Validation': {'rocauc': 0.5550962669018225}, 'Test': {'rocauc': 0.579609494196489}}\n",
      "=====Epoch 5\n",
      "Training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f74013bb74564b9fa9c2098d7e16acfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb1c23c6eea49e4b5efd9b2abc9297e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/1029 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86ab1bcfb5d4453a8549a6aee51213fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fb0d420acb49aeaf5f09892b8a8cb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/129 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Train': {'rocauc': 0.5561585072542159}, 'Validation': {'rocauc': 0.5796406525573192}, 'Test': {'rocauc': 0.5984684910871202}}\n",
      "Finished training!\n",
      "Best validation score: 0.6131993435234175\n",
      "Test score: 0.6165144170416578\n"
     ]
    }
   ],
   "source": [
    "cls_criterion = torch.nn.BCEWithLogitsLoss()\n",
    "reg_criterion = torch.nn.MSELoss()\n",
    "\n",
    "def train(model, device, loader, optimizer, task_type):\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1 or batch.batch[-1] == 0:\n",
    "            pass\n",
    "        else:\n",
    "            pred = model(batch)\n",
    "            optimizer.zero_grad()\n",
    "            ## ignore nan targets (unlabeled) when computing training loss.\n",
    "            is_labeled = batch.y == batch.y\n",
    "            if \"classification\" in task_type: \n",
    "                loss = cls_criterion(pred.to(torch.float32)[is_labeled], batch.y.to(torch.float32)[is_labeled])\n",
    "            else:\n",
    "                loss = reg_criterion(pred.to(torch.float32)[is_labeled], batch.y.to(torch.float32)[is_labeled])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "def eval(model, device, loader, evaluator):\n",
    "    model.eval()\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(loader, desc=\"Iteration\")):\n",
    "        batch = batch.to(device)\n",
    "\n",
    "        if batch.x.shape[0] == 1:\n",
    "            pass\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                pred = model(batch)\n",
    "\n",
    "            y_true.append(batch.y.view(pred.shape).detach().cpu())\n",
    "            y_pred.append(pred.detach().cpu())\n",
    "\n",
    "    y_true = torch.cat(y_true, dim = 0).numpy()\n",
    "    y_pred = torch.cat(y_pred, dim = 0).numpy()\n",
    "\n",
    "    input_dict = {\"y_true\": y_true, \"y_pred\": y_pred}\n",
    "\n",
    "    return evaluator.eval(input_dict)\n",
    "\n",
    "\n",
    "class Args():\n",
    "    def __init__(self):\n",
    "        self.device = 0\n",
    "        self.gnn='gin'\n",
    "        self.drop_ratio = 0.5\n",
    "        self.num_layers=5\n",
    "        self.emb_dim = 300\n",
    "        self.batch_size = 32\n",
    "        self.epochs = 100\n",
    "        self.num_workers=0\n",
    "        self.dataset= \"ogbg-molhiv\"\n",
    "        self.feature=\"full\"\n",
    "        self.filename=\"\"\n",
    "\n",
    "        \n",
    "def get_terminal_args():\n",
    "    parser = argparse.ArgumentParser(description='GNN baselines on ogbgmol* data with Pytorch Geometrics')\n",
    "    parser.add_argument('--device', type=int, default=0,\n",
    "                        help='which gpu to use if any (default: 0)')\n",
    "    parser.add_argument('--gnn', type=str, default='gin-virtual',\n",
    "                        help='GNN gin, gin-virtual, or gcn, or gcn-virtual (default: gin-virtual)')\n",
    "    parser.add_argument('--drop_ratio', type=float, default=0.5,\n",
    "                        help='dropout ratio (default: 0.5)')\n",
    "    parser.add_argument('--num_layer', type=int, default=5,\n",
    "                        help='number of GNN message passing layers (default: 5)')\n",
    "    parser.add_argument('--emb_dim', type=int, default=300,\n",
    "                        help='dimensionality of hidden units in GNNs (default: 300)')\n",
    "    parser.add_argument('--batch_size', type=int, default=32,\n",
    "                        help='input batch size for training (default: 32)')\n",
    "    parser.add_argument('--epochs', type=int, default=100,\n",
    "                        help='number of epochs to train (default: 100)')\n",
    "    parser.add_argument('--num_workers', type=int, default=0,\n",
    "                        help='number of workers (default: 0)')\n",
    "    parser.add_argument('--dataset', type=str, default=\"ogbg-molhiv\",\n",
    "                        help='dataset name (default: ogbg-molhiv)')\n",
    "\n",
    "    parser.add_argument('--feature', type=str, default=\"full\",\n",
    "                        help='full feature or simple feature')\n",
    "    parser.add_argument('--filename', type=str, default=\"\",\n",
    "                        help='filename to output result (default: )')\n",
    "    args = parser.parse_args()\n",
    "    return args\n",
    "def main():\n",
    "    # Training settings\n",
    "    ## if obtain settings from terminal\n",
    "    #args = get_terminal_args()\n",
    "    args = Args()\n",
    "    args.epochs = 5\n",
    "    \n",
    "\n",
    "    device = torch.device(\"cuda:\" + str(args.device)) if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "    ### automatic dataloading and splitting\n",
    "    dataset = PygGraphPropPredDataset(name = args.dataset)\n",
    "\n",
    "    if args.feature == 'full':\n",
    "        pass \n",
    "    elif args.feature == 'simple':\n",
    "        print('using simple feature')\n",
    "        # only retain the top two node/edge features\n",
    "        dataset.data.x = dataset.data.x[:,:2]\n",
    "        dataset.data.edge_attr = dataset.data.edge_attr[:,:2]\n",
    "\n",
    "    split_idx = dataset.get_idx_split()\n",
    "\n",
    "    ### automatic evaluator. takes dataset name as input\n",
    "    evaluator = Evaluator(args.dataset)\n",
    "\n",
    "    train_loader = DataLoader(dataset[split_idx[\"train\"]], batch_size=args.batch_size, shuffle=True, num_workers = args.num_workers)\n",
    "    valid_loader = DataLoader(dataset[split_idx[\"valid\"]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "    test_loader = DataLoader(dataset[split_idx[\"test\"]], batch_size=args.batch_size, shuffle=False, num_workers = args.num_workers)\n",
    "    \n",
    "    if args.gnn == 'gin':\n",
    "        model = GINGraphPooling( num_tasks = dataset.num_tasks, num_layers = args.num_layers, emb_dim = args.emb_dim, drop_ratio = args.drop_ratio,).to(device)\n",
    "    else:\n",
    "        raise ValueError('Invalid GNN type')\n",
    "\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    valid_curve = []\n",
    "    test_curve = []\n",
    "    train_curve = []\n",
    "\n",
    "    for epoch in range(1, args.epochs + 1):\n",
    "        print(\"=====Epoch {}\".format(epoch))\n",
    "        print('Training...')\n",
    "        train(model, device, train_loader, optimizer, dataset.task_type)\n",
    "\n",
    "        print('Evaluating...')\n",
    "        train_perf = eval(model, device, train_loader, evaluator)\n",
    "        valid_perf = eval(model, device, valid_loader, evaluator)\n",
    "        test_perf = eval(model, device, test_loader, evaluator)\n",
    "\n",
    "        print({'Train': train_perf, 'Validation': valid_perf, 'Test': test_perf})\n",
    "\n",
    "        train_curve.append(train_perf[dataset.eval_metric])\n",
    "        valid_curve.append(valid_perf[dataset.eval_metric])\n",
    "        test_curve.append(test_perf[dataset.eval_metric])\n",
    "\n",
    "    if 'classification' in dataset.task_type:\n",
    "        best_val_epoch = np.argmax(np.array(valid_curve))\n",
    "        best_train = max(train_curve)\n",
    "    else:\n",
    "        best_val_epoch = np.argmin(np.array(valid_curve))\n",
    "        best_train = min(train_curve)\n",
    "\n",
    "    print('Finished training!')\n",
    "    print('Best validation score: {}'.format(valid_curve[best_val_epoch]))\n",
    "    print('Test score: {}'.format(test_curve[best_val_epoch]))\n",
    "\n",
    "    if not args.filename == '':\n",
    "        torch.save({'Val': valid_curve[best_val_epoch], 'Test': test_curve[best_val_epoch], 'Train': train_curve[best_val_epoch], 'BestTrain': best_train}, args.filename)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    torch.manual_seed(2021)\n",
    "    main()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 作业\n",
    "- 请画出下方图片中的6号、3号和5号节点的从1层到3层到WL子树。\n",
    "![image.png](./image/2560px-6n-graf.svg.png)\n",
    "参考：[Weisfeiler-Leman test与WL subtree kernel](https://blog.csdn.net/qq_34138003/article/details/108172823)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.jpg](./image/Task6作业.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "289.275px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
